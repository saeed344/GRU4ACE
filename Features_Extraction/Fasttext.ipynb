{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNyBPDuobUkyaHxN/UyMbQy"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Bqo1DwpU-G1Y","executionInfo":{"status":"ok","timestamp":1726681873100,"user_tz":-120,"elapsed":25152,"user":{"displayName":"Saeed Ahmed","userId":"16724720564507897686"}},"outputId":"41244e90-b329-4ec9-d34a-9557e605bb05"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n",""]},{"cell_type":"code","source":["!pip install transformers"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sIEcAwS8-O73","executionInfo":{"status":"ok","timestamp":1726681829713,"user_tz":-120,"elapsed":7469,"user":{"displayName":"Saeed Ahmed","userId":"16724720564507897686"}},"outputId":"74071c87-a8c1-4967-f0aa-648cb5712ee2"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.7)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n","Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n"]}]},{"cell_type":"code","source":["import os\n","import re\n","import sys\n","import pandas as pd\n","import numpy as np\n","from gensim.models import Word2Vec\n","from collections import Counter\n","\n","\n","def read_peptide_sequences(file):\n","    if not os.path.exists(file):\n","        print(f'Error: file {file} does not exist.')\n","        sys.exit(1)\n","\n","    with open(file) as f:\n","        records = f.read()\n","\n","    if '>' not in records:\n","        print(f'Error: the input file {file} seems not in FASTA format!')\n","        sys.exit(1)\n","\n","    records = records.split('>')[1:]\n","    peptide_sequences = []\n","    for fasta in records:\n","        array = fasta.split('\\n')\n","        header, sequence = array[0], ''.join(array[1:]).upper()\n","        peptide_sequences.append(sequence)\n","\n","    return peptide_sequences\n","\n","def extract_features(peptide_sequences, vector_size=100, window=5, min_count=1):\n","    # Prepare data for Word2Vec\n","    tokenized_sequences = [list(sequence) for sequence in peptide_sequences]\n","\n","    # Train Word2Vec model\n","    model = Word2Vec(tokenized_sequences, vector_size=vector_size, window=window, min_count=min_count)\n","\n","    # Create a vocabulary list\n","    vocabulary = list(model.wv.index_to_key)\n","\n","    # Extract BoW + Word2Vec features\n","    features = []\n","    for sequence in tokenized_sequences:\n","        # Bag of Words representation\n","        bow = Counter(sequence)\n","        bow_vector = [bow[token] for token in vocabulary]\n","\n","        # Word2Vec representation\n","        word2vec_vector = np.zeros(vector_size)\n","        for token in sequence:\n","            if token in model.wv:\n","                word2vec_vector += model.wv[token]\n","        word2vec_vector /= len(sequence)\n","\n","        # Combine BoW and Word2Vec vectors\n","        combined_vector = np.concatenate([bow_vector, word2vec_vector])\n","        features.append(combined_vector)\n","\n","    return np.array(features), vocabulary\n","\n","def main():\n","    # File paths\n","    path = '/content/drive/MyDrive/Watashara_Projects/TIP/'\n","    file_path = path+'Features_extraction/TR_IND_Pos_Neg.fasta'\n","    output_csv = path + 'features/Fasttext_features_TIP.csv'\n","\n","    # Read peptide sequences\n","    peptide_sequences = read_peptide_sequences(file_path)\n","\n","    # Extract features using BoW + Word2Vec\n","    features, vocabulary = extract_features(peptide_sequences)\n","\n","    # Create a DataFrame with the combined features\n","    bow_columns = [f'bow_{token}' for token in vocabulary]\n","    word2vec_columns = [f'word2vec_{i}' for i in range(features.shape[1] - len(vocabulary))]\n","    columns = bow_columns + word2vec_columns\n","\n","    features_df = pd.DataFrame(features, columns=columns)\n","    features_df.to_csv(output_csv, index=False)\n","\n","    print(\"Features extracted and saved to CSV successfully.\")\n","    print(features)\n","\n","if __name__ == \"__main__\":\n","    main()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":311},"id":"srRm3d8B-P3s","executionInfo":{"status":"error","timestamp":1726681897844,"user_tz":-120,"elapsed":2298,"user":{"displayName":"Saeed Ahmed","userId":"16724720564507897686"}},"outputId":"307646a4-17ce-48ce-de80-6f934d7e2584"},"execution_count":5,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'output_file' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-4d4c177ca625>\u001b[0m in \u001b[0;36m<cell line: 84>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-5-4d4c177ca625>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0mfeatures_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m     \u001b[0mfeatures_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Features extracted and saved to CSV successfully.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'output_file' is not defined"]}]}]}